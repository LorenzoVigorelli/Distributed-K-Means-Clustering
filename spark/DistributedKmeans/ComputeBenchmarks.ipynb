{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95b7eed2-1d38-40a6-825a-d9fc201f29df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_kddcup99\n",
    "from pyspark.sql import SparkSession\n",
    "from time import time, sleep\n",
    "import subprocess\n",
    "import pprint\n",
    "import sys\n",
    "import logging\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2500614-e910-4c13-b4bd-033ecca6017b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the spark warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "logging.getLogger('py4j').setLevel(logging.ERROR) \n",
    "logging.getLogger('pyspark').setLevel(logging.ERROR) \n",
    "log4j_conf_path = \"file:///home/quivigorelli/Distributed-K-Means-Clustering/spark/DistributedKmeans/log4j.properties\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6fb5bf-cf09-44b6-81ec-4cedb6529c70",
   "metadata": {},
   "source": [
    "Global hyperparameters and data paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "826cb1c4-f323-43b0-a155-f6dec45e08a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files for reading and writing of data dictionaries\n",
    "pickle_fileP = 'dataP/log1P_C11.pkl' # Parallel initialization data\n",
    "pickle_fileR = 'dataR/log1U_C11.pkl' # Random initialization data\n",
    "\n",
    "# Setting seeds for reproducibility\n",
    "np.random.seed(12345)\n",
    "spark_seed = 54321\n",
    "\n",
    "# Number of partitions \n",
    "nSlices = [256] # done 2, 4, 8, 16, 32, 64, 128, 256\n",
    "\n",
    "# Size of considered subset\n",
    "subLen = 300_000\n",
    "\n",
    "# Maximum number of iterations in Lloyds algorithm\n",
    "lloydsMaxIterations=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1426166-735a-4146-9df4-3bf35d3e6c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def labelToInt(label):\n",
    "    '''\n",
    "    Map from set of labels in original dataset (`strings`) into set of natural numbers (`int`) for easier manipulation of rdd\n",
    "    '''\n",
    "    uniqueLabels=list(np.unique(y))\n",
    "    return uniqueLabels.index(label)\n",
    "\n",
    "\n",
    "def deleteBytes(datum):\n",
    "    '''\n",
    "    Clean dataset from categorical attributes, leaving numerical ones\n",
    "    Arguments:\n",
    "    One datum of the rdd.\n",
    "    Return:\n",
    "    Updated datum.\n",
    "    '''\n",
    "    x = datum[1][\"x\"]\n",
    "    mask = [type(i) != bytes for i in x]\n",
    "    datum[1][\"x\"] = np.asarray(x[mask])\n",
    "    print(x)\n",
    "    print(mask)\n",
    "    return datum\n",
    "\n",
    "\n",
    "def localPlusPlusInit(points, k): \n",
    "    '''\n",
    "    KMeans++ initialization.\n",
    "    Arguments:\n",
    "    `points`: array (n, dim) of points to be clustered;\n",
    "    `k`: desired number of centroids. \n",
    "    Returns:\n",
    "    Initial array (k, dim) of centroids, k<=n.\n",
    "    '''\n",
    "    # Sample one point uniformly from points array\n",
    "    C=points[np.random.choice(points.shape[0])]\n",
    "    C=C[np.newaxis, :]\n",
    "    \n",
    "    for _ in range(k):\n",
    "        # Compute array (n,1) of probabilities associated to each point\n",
    "        probs=np.min(np.sum((points[:,:,np.newaxis]-C.T[np.newaxis,:,:])**2, axis=1), axis=1).flatten()\n",
    "        # Normalize probability distribution\n",
    "        probs=probs/np.sum(probs)\n",
    "        \n",
    "        # Draw one new centroid according to distrbution\n",
    "        nextCentroid=points[np.random.choice(points.shape[0], p=probs)][np.newaxis,:]\n",
    "        # Add centroid to array\n",
    "        C=np.vstack((C, nextCentroid))\n",
    "    return C\n",
    "\n",
    "\n",
    "def weightedAverage(group):\n",
    "    \"\"\"\n",
    "    Compute weighted average of a group from a pd.DataFrame with point coordinates, weights, clusterId.\n",
    "    Utilized in local (non-distributed) version of Lloyds algorithm, needed also in K-Means//\n",
    "    \"\"\"\n",
    "    weight_column='weights'\n",
    "    groupby_column='clusterId'\n",
    "    columns_to_average = group.columns.difference([weight_column, groupby_column])\n",
    "    weighted_averages = group[columns_to_average].multiply(group[weight_column], axis=0).sum() / group[weight_column].sum()\n",
    "    return weighted_averages\n",
    "\n",
    "\n",
    "def localLloyds(points, k, C_init=None, weights=None, n_iterations=100, logDict=None):\n",
    "    \"\"\"\n",
    "    Local (non-distributed) Lloyds algorithm\n",
    "    Arguments:\n",
    "    `points`: array (n, dim) of points to cluster;\n",
    "    `k`: number of desired clusters;\n",
    "    `C_init`: optional, array (k, dim) of initial centroids\n",
    "    `weights`: optional, weights for weighted average in centroid re-computing;\n",
    "    `n_iterations`: optional, number of iteration in lloyds algorithm;\n",
    "    `logDict`: optional, dictionary {'CostsKmeans', 'tIterations', 'tTotal'} to store cost and time info.\n",
    "    Return:\n",
    "    Array of expected centroids.\n",
    "    \"\"\"\n",
    "    t0 = time()\n",
    "\n",
    "    # Storing cost and time info\n",
    "    my_kMeansCosts = []\n",
    "    tIterations = []\n",
    "    \n",
    "    df=pd.DataFrame(points)\n",
    "\n",
    "    # If weights not given, assume uniform weights for points\n",
    "    if weights is None:\n",
    "        weights=np.ones(shape=len(points))\n",
    "    df['weights']=weights\n",
    "    df['clusterId']=np.zeros(shape=len(points))\n",
    "\n",
    "    # If no C_init, default to K-Means++ initialization\n",
    "    if C_init is None:\n",
    "        C=localPlusPlusInit(points, k)\n",
    "    else:\n",
    "        C=C_init\n",
    "   \n",
    "    clusterId=np.argmin(np.sum((points[:,:,np.newaxis]-C.T[np.newaxis,:,:])**2, axis=1), axis=1)\n",
    "    for iteration in range(n_iterations):\n",
    "        t1=time()\n",
    "\n",
    "        # Compute centroid given cluster\n",
    "        df['clusterId']=clusterId\n",
    "        C_df=df.groupby('clusterId')\\\n",
    "            .apply(weightedAverage)\\\n",
    "            .reset_index()\n",
    "\n",
    "        # Compute cluster given centroid\n",
    "        C_array=C_df[C_df.columns.difference(['weights', 'clusterId'])].reset_index(drop=True).to_numpy()\n",
    "        squared_distances=np.sum((points[:,:,np.newaxis]-C_array.T[np.newaxis,:,:])**2, axis=1)\n",
    "        clusterId=np.argmin(squared_distances, axis=1)\n",
    "        my_cost=sum(squared_distances[np.arange(len(squared_distances)), clusterId])\n",
    "\n",
    "        my_kMeansCosts.append(my_cost)\n",
    "        t2 = time()\n",
    "        \n",
    "        tIteration = t2 - t1\n",
    "        tIterations.append(tIteration)\n",
    "\n",
    "    tEnd = time()\n",
    "    tTotal = tEnd - t0\n",
    "\n",
    "    # Store cost and time info\n",
    "    if logDict is not None:\n",
    "        logDict[\"CostsKmeans\"] = my_kMeansCosts\n",
    "        logDict[\"tIterations\"] = tIterations\n",
    "        logDict[\"tTotal\"] = tTotal\n",
    "    \n",
    "    return C_array \n",
    "\n",
    "\n",
    "def minmaxRescale(datum, minS, maxS):\n",
    "    \"\"\"\n",
    "    Rescale datum in [0,1] interval for better clusterization\n",
    "    Arguments:\n",
    "    `datum`: see rdd format;\n",
    "    `minS`: array of min coordinate value among points for each attribute;\n",
    "    `maxS`: as `minS` with max.\n",
    "    Return:\n",
    "    Updated datum.\n",
    "    \"\"\"\n",
    "    mask = np.array(minS < maxS).astype(bool)\n",
    "    feature = datum[1][\"x\"] \n",
    "    feature = (feature[mask] - minS[mask])/(maxS[mask] - minS[mask])\n",
    "    return (datum[0], {\"x\": feature, \"y\": datum[1][\"y\"], \"d2\":datum[1][\"d2\"]}) \n",
    "\n",
    "\n",
    "def selectCluster(datum, C, updateDistances=True):\n",
    "    \"\"\"\n",
    "    Associate datum to its centroid and optionally updates squared distance between them.\n",
    "    Arguments:\n",
    "    `datum`: see rdd format;\n",
    "    `C`: array (k, len(datum[1][\"x\"]));\n",
    "    `updateDistances`: if True, updates `datum[1][\"d2\"]` with squared distance between datum point and closest centroid in C.\n",
    "    Return:\n",
    "    Updated datum.\n",
    "    \"\"\"\n",
    "    distances = np.sum((datum[1][\"x\"] - C)**2, axis=1)\n",
    "    print('distances: ',distances)\n",
    "    clusterId = np.argmin(distances)\n",
    "    if updateDistances is True:\n",
    "        return (clusterId, {'x':datum[1]['x'], 'y':datum[1]['y'], 'd2':distances[clusterId]})\n",
    "    else:\n",
    "        return (clusterId, datum[1])\n",
    "\n",
    "\n",
    "def updateCentroids(Rdd):\n",
    "    \"\"\"\n",
    "    Update centroids as spatial average of cluster points\n",
    "    Argument:\n",
    "    `Rdd`: see rdd format;\n",
    "    Return:\n",
    "    Updated array of centroids.\n",
    "    \"\"\"\n",
    "    C=Rdd.mapValues(lambda xy: (xy['x'], 1))\\\n",
    "              .reduceByKey(lambda a,b : (a[0]+b[0], a[1]+b[1]))\\\n",
    "              .mapValues(lambda a:a[0]/a[1])\\\n",
    "              .values()\\\n",
    "              .collect() \n",
    "    C=np.array(C) #check later more carefully if causes some overhead\n",
    "    return C\n",
    "\n",
    "\n",
    "def updateDistances(Rdd, C):\n",
    "    \"\"\"\n",
    "    Update Rdd with square distances from centroids, given Rdd with clusters already assigned to each point\n",
    "    Arguments:\n",
    "    `Rdd`: see rdd format;\n",
    "    `C`: array of cluster centroids.\n",
    "    Return:\n",
    "    Updated rdd.\n",
    "    \"\"\"\n",
    "    def datumUpdate(datum, C):\n",
    "        '''\n",
    "        Update a datum of the rdd with distance from assigned centroid\n",
    "        '''\n",
    "        d2=np.sum((datum[1]['x']-C[datum[0]])**2)\n",
    "        #return datum\n",
    "        return (datum[0], {\"x\": datum[1][\"x\"], \"y\": datum[1][\"y\"], \"d2\":d2})\n",
    "    Rdd=Rdd.map(lambda datum:datumUpdate(datum, C))\n",
    "    return Rdd\n",
    "\n",
    "\n",
    "def cost(Rdd):\n",
    "    \"\"\"\n",
    "    Calculate global cost of clusterization, from an Rdd with distances from centroids already updated\n",
    "    \"\"\"\n",
    "    my_cost=Rdd.map(lambda datum : datum[1]['d2'])\\\n",
    "               .reduce(lambda a,b: a+b)\n",
    "    return my_cost \n",
    "\n",
    "\n",
    "def kMeans(Rdd, C_init, maxIterations, logParallelKmeans=None):\n",
    "    \"\"\"\n",
    "    Distributed (parallel) Lloyds algorithm\n",
    "    Arguments:\n",
    "    `Rdd`: see rdd format;\n",
    "    `C_init`: array (k, dim) of initial centroids;\n",
    "    `maxIterations`: max number of iterations;\n",
    "    `logParallelKmeans`: optional, dictionary {'CostsKmeans', 'tIterations', 'tTotal'} to store cost and time info.\n",
    "    Return:\n",
    "    Array of expected centroids.\n",
    "    \"\"\"\n",
    "    \n",
    "    t0 = time()\n",
    "\n",
    "    # Storing cost and time info\n",
    "    my_kMeansCosts = []\n",
    "    tIterations = []\n",
    "    C=C_init\n",
    "\n",
    "    for t in range(maxIterations):\n",
    "        t1 = time()\n",
    "        RddCached = Rdd.map(lambda datum: selectCluster(datum, C)).persist() ###\n",
    "        \n",
    "        # Now we compute the new centroids by calculating the averages of points belonging to the same cluster.\n",
    "        C=updateCentroids(RddCached)\n",
    "        my_cost = cost(RddCached)\n",
    "        \n",
    "        my_kMeansCosts.append(my_cost)\n",
    "        t2 = time()\n",
    "        \n",
    "        tIteration = t2 - t1\n",
    "        tIterations.append(tIteration)\n",
    "        \n",
    "        #RddCached.unpersist() \n",
    "\n",
    "        # Break loop if convergence of cost is reached\n",
    "        if (len(my_kMeansCosts) > 1) and (my_kMeansCosts[-1] > 0.999*my_kMeansCosts[-2]):\n",
    "            break\n",
    "\n",
    "    tEnd = time()\n",
    "    tTotal = tEnd - t0\n",
    "\n",
    "    # Store cost and time info in argument dictionary\n",
    "    if logParallelKmeans is not None:\n",
    "        logParallelKmeans[\"CostsKmeans\"] = my_kMeansCosts\n",
    "        logParallelKmeans[\"tIterations\"] = tIterations\n",
    "        logParallelKmeans[\"tTotal\"] = tTotal\n",
    "\n",
    "    return C\n",
    "\n",
    "\n",
    "def naiveInitFromSet(Rdd, k, logNaiveInit=None, spark_seed=54321):\n",
    "    \"\"\"\n",
    "    Uniform sampling of k points from Rdd\n",
    "    Arguments:\n",
    "    `Rdd`: see rdd structure;\n",
    "    `k`: desired number of clusters;\n",
    "    `spark_seed`: optional, seed for spark random sampling;\n",
    "    `logNaiveInit`: optional, dictionary {'tTotal'} to store time info.\n",
    "    Return:\n",
    "    Initial array (k, dim) of centroids.\n",
    "    \"\"\"\n",
    "    t0 = time()\n",
    "    # Sampling. Replacement is set to False to avoid coinciding centroids BUT no guarantees that in the original dataset all points are distinct!!!\n",
    "    kSubset=Rdd.takeSample(False, k, seed=spark_seed)\n",
    "    C_init=np.array([datum[1]['x'] for datum in kSubset])\n",
    "\n",
    "    tEnd = time()\n",
    "    \n",
    "    if logNaiveInit is not None:\n",
    "        logNaiveInit[\"tTotal\"] = tEnd - t0\n",
    "        \n",
    "    return C_init\n",
    "\n",
    "\n",
    "def naiveInitFromSpace(k, dim):\n",
    "    \"\"\"\n",
    "    Uniform drawing of k points from euclidean space assuming the Rdd has been mapped into a [0,1]^dim space\n",
    "    Arguments:\n",
    "    `k`: desired number of clusters;\n",
    "    `dim`: dimensionality of points space.\n",
    "    Return:\n",
    "    Initial array (k, dim) of centroids.\n",
    "    \"\"\"\n",
    "    C_init=np.random.uniform(size=(k,dim))\n",
    "    return C_init\n",
    "\n",
    "\n",
    "def parallelInit(Rdd, k, l, logParallelInit=None):\n",
    "    \"\"\"\n",
    "    Parallel initialization\n",
    "    Arguments:\n",
    "    `Rdd`: see rdd structure;\n",
    "    `k`: desired number of clusters;\n",
    "    `l`: coefficient to adjust sampling probability in order to obtain at least k centroids;\n",
    "    `logParallelInit`: optional, dictionary {'CostsKmeans', 'tIterations', 'tTotal'} to store cost and time info.\n",
    "    Return:\n",
    "    Initial array (k, dim) of centroids.\n",
    "    \"\"\"\n",
    "    t0 = time()\n",
    "    \n",
    "    # initialize C as a point in the dataset\n",
    "    C=naiveInitFromSet(Rdd, 1) \n",
    "    \n",
    "    # associate each datum to the only centroid (computed before) and computed distances and cost\n",
    "    Rdd=Rdd.map(lambda datum : (0, datum[1]))\n",
    "    Rdd=updateDistances(Rdd, C).persist() ###\n",
    "    \n",
    "    my_cost=cost(Rdd)\n",
    "\n",
    "    # number of iterations (log(cost))\n",
    "    n_iterations=int(np.log(my_cost))\n",
    "    if(n_iterations<1): n_iterations=1\n",
    "    \n",
    "    tSamples = []\n",
    "    tCentroids = []\n",
    "    CostInits = [my_cost]\n",
    "\n",
    "    # iterative sampling of the centroids\n",
    "    for _ in range(n_iterations):\n",
    "\n",
    "        t1=time()\n",
    "        # sample C' according to the probability\n",
    "        C_prime=Rdd.filter(lambda datum : np.random.uniform()<l*datum[1]['d2']/my_cost)\\\n",
    "                   .map(lambda datum : datum[1]['x'])\\\n",
    "                   .collect()\n",
    "        C_prime=np.array(C_prime)\n",
    "        t2=time()\n",
    "\n",
    "        # stack C and C', update distances, centroids, and cost\n",
    "        if (C_prime.shape[0]>0):\n",
    "            C=np.vstack((C, C_prime))\n",
    "            \n",
    "            #Rdd.unpersist() ###\n",
    "            Rdd=Rdd.map(lambda datum: selectCluster(datum, C)).persist() ###\n",
    "            \n",
    "            my_cost=cost(Rdd)\n",
    "        t3=time()\n",
    "\n",
    "        tSample = t2 -t1\n",
    "        tCentroid = t3 - t2\n",
    "        tSamples.append(tSample)\n",
    "        tCentroids.append(tCentroid)\n",
    "        CostInits.append(my_cost)\n",
    "       \n",
    "    #erase centroids sampled more than once \n",
    "    C=C.astype(float)\n",
    "    C=np.unique(C, axis=0)\n",
    "    Rdd=Rdd.map(lambda datum: selectCluster(datum, C))\n",
    "    \n",
    "    #compute weights of centroids (sizes of each cluster) and put them in a list whose index is same centroid index as C\n",
    "    wx=Rdd.countByKey()\n",
    "    weights=np.zeros(len(C))\n",
    "    weights[[list(wx.keys())]]=[list(wx.values())]\n",
    "    \n",
    "    #subselection of k centroids from C, using local Lloyds algorithm with k-means++ initialization\n",
    "    if C.shape[0]<=k:\n",
    "        C_init=C\n",
    "    else:\n",
    "        C_init=localLloyds(C, k, weights=weights, n_iterations=100) #can be set to lloydsMaxIterations for consistency TODO\n",
    "\n",
    "    tEnd = time()\n",
    "    \n",
    "    if logParallelInit is not None:\n",
    "        logParallelInit[\"tSamples\"] = tSamples\n",
    "        logParallelInit[\"tCentroids\"] = tCentroids\n",
    "        logParallelInit[\"CostInit\"] = CostInits\n",
    "        logParallelInit[\"tTotal\"] = tEnd - t0\n",
    "\n",
    "    #Rdd.unpersist() ###\n",
    "    return C_init\n",
    "\n",
    "def predictedCentroidsLabeler(C_expected, C_predicted):\n",
    "    \"\"\"\n",
    "    Associate expected and predicted centroids based on distance.\n",
    "    Parameters:\n",
    "    `C_expected`: array (k, dim) of expected centroids;\n",
    "    `C_predicted`: array (k,dim) of predicted centroids;\n",
    "    Return:\n",
    "    List of labels, one for each expected centroid and pointing to its nearest predicted centroid;\n",
    "    List of corresponding distances.\n",
    "    \"\"\"\n",
    "    # Compute the distance matrix\n",
    "    distMatrix=np.sum((C_expected[:,:,np.newaxis]-C_predicted.T[np.newaxis, :,:])**2,axis=1)\n",
    "    # The labeler i-th entry j, tells that i-th centroid of C_expected is associated to j-th element of C_predicted\n",
    "    labeler=np.argmin(distMatrix,axis=1)\n",
    "    # Square distance of element of C_expected to nearest point in C_predicted\n",
    "    distances=np.sqrt(np.array(distMatrix[np.arange(len(distMatrix)),labeler]).astype(float))\n",
    "    return labeler, distances\n",
    "\n",
    "\n",
    "def nearestCentroidDistances(C):\n",
    "    \"\"\"\n",
    "    Associate each centroid to the distance of the nearest one\n",
    "    Parameters:\n",
    "    `C`:  array (k, dim) of centroids;\n",
    "    Return:\n",
    "    List of labels, one for each centroid and pointing to its nearest centroid;\n",
    "    List of corresponding distances.\n",
    "    \"\"\"\n",
    "    # Compute the distance matrix\n",
    "    distMatrix=np.sum((C[:,:,np.newaxis]-C.T[np.newaxis, :,:])**2,axis=1)\n",
    "    distMatrix+=np.diag(np.repeat(np.inf, distMatrix.shape[0]))\n",
    "    \n",
    "    # The labeler i-th entry j, tells that i-th centroid of C_expected is associated to j-th element of C_predicted\n",
    "    labeler=np.argmin(distMatrix,axis=1)\n",
    "    \n",
    "    # Square distance of element of C_expected to nearest point in C_predicted\n",
    "    distances=np.sqrt(np.array(distMatrix[np.arange(distMatrix.shape[0]),labeler]).astype(float))\n",
    "    return labeler, distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "741807da-d71c-4192-973b-3207e1d23b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/08 18:07:24 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The iteration with 256 number of partition started at time 1720462046.8569777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished the pre-steps after 25.964742422103882 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished the initialization after 1078.2120974063873 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The iteration with 256 number of partition ended at time 1720463233.6977935 after 1186.840815782547 seconds\n",
      "The iteration with 256 number of partition started at time 1720463235.0972173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished the pre-steps after 20.938359260559082 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished the initialization after 9.937275171279907 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The iteration with 256 number of partition ended at time 1720463487.6936898 after 252.59647250175476 seconds\n",
      "CPU times: user 9.72 s, sys: 1.59 s, total: 11.3 s\n",
      "Wall time: 24min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### SPARK SETUP ###\n",
    "\n",
    "# Build a spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"spark://spark-master:7077\")\\\n",
    "    .appName(\"Clustering\")\\\n",
    "    .config(\"spark.executor.memory\", \"7g\")\\\n",
    "    .config(\"spark.driver.extraJavaOptions\", f\"-Dlog4j.configuration=file:{log4j_conf_path}\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Create a spark context\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "\n",
    "# Eventually clear old data (if re-running)\n",
    "spark.catalog.clearCache() \n",
    "# for (id, rdd) in sc._jsc.getPersistentRDDs().items():\n",
    "#     rdd.unpersist()\n",
    "\n",
    "#### IMPORT THE DATA SET ####\n",
    "data = fetch_kddcup99(return_X_y = True, percent10 = True) # default percent10=True\n",
    "\n",
    "# collect samples and features (target)\n",
    "x = data[0]\n",
    "y = data[1] \n",
    "\n",
    "# Shuffle\n",
    "shuffled_indices = np.random.permutation(len(x))\n",
    "x=x[shuffled_indices]\n",
    "y=y[shuffled_indices]\n",
    "\n",
    "# cut the data fro memory reasons\n",
    "x = x[:subLen,]\n",
    "y = y[:subLen]\n",
    "\n",
    "for nSlice in nSlices:\n",
    "    ### PARALLEL ###\n",
    "\n",
    "    # Open file if exists\n",
    "    sleep(1)\n",
    "    if os.path.isfile(pickle_fileP):\n",
    "        with open(pickle_fileP, \"rb\") as f:\n",
    "            logParallel = pickle.load(f)\n",
    "            totalLogParallelInit, totalLogParallelKmeans, tDurationsParallel, tPreOperationsParallel = logParallel.values()\n",
    "    else:\n",
    "        totalLogParallelInit = {}\n",
    "        totalLogParallelKmeans = {}\n",
    "        tDurationsParallel = {}\n",
    "        tPreOperationsParallel = {}\n",
    "\n",
    "    # Start the algorithm\n",
    "    tInit = time() # compute the time of the beginning of the iteration over the number of partitions\n",
    "    print(f\"The iteration with {nSlice} number of partition started at time {tInit}\")\n",
    "    \n",
    "    # Parallelize over nSlice partitions\n",
    "    Rdd = sc.parallelize([(None, {\"x\": x[i],\"y\": y[i], \"d2\":None}) for i in range(len(y))], numSlices = nSlice)\n",
    "\n",
    "    # Cut the categorical attributes\n",
    "    Rdd = Rdd.map(deleteBytes)\\\n",
    "             .persist()\n",
    "\n",
    "    # Setting the theoretical number of clusters\n",
    "    kTrue = Rdd.map(lambda datum: datum[1][\"y\"])\\\n",
    "               .distinct()\\\n",
    "               .count()\n",
    "    \n",
    "    # Rescale the RDD over the max\n",
    "    maxS = Rdd.map(lambda datum: datum[1][\"x\"])\\\n",
    "           .reduce(lambda a, b: np.maximum(a, b))\n",
    "    minS = Rdd.map(lambda datum: datum[1][\"x\"])\\\n",
    "           .reduce(lambda a, b: np.minimum(a, b))\n",
    "\n",
    "    Rdd = Rdd.map(lambda datum: minmaxRescale(datum, minS, maxS))\\\n",
    "             .persist()\n",
    "    \n",
    "    # Setting up the input and output information for the algorithm\n",
    "    logParallelInit = {}\n",
    "    logParallelKmeans = {}\n",
    "\n",
    "    # Setup k and l\n",
    "    k=kTrue\n",
    "    l=k*2 \n",
    "    \n",
    "    tInitI = time()\n",
    "\n",
    "    tPreOperation = tInitI - tInit\n",
    "    print(f\"Finished the pre-steps after {tPreOperation} seconds\")\n",
    "          \n",
    "    # Initialization kMeans //\n",
    "    C_init = parallelInit(Rdd, k, l, logParallelInit)\n",
    "    \n",
    "    tInitialization = time() - tInitI\n",
    "    print(f\"Finished the initialization after {tInitialization} seconds\")\n",
    "    \n",
    "    # Run the k-means alghoritm\n",
    "    C = kMeans(Rdd, C_init, lloydsMaxIterations, logParallelKmeans)\n",
    "    \n",
    "    # Time information\n",
    "    tEnd = time() # compute the time of the end of the iteration over the number of partitions\n",
    "    tDuration = tEnd - tInit\n",
    "    \n",
    "    print(f\"The iteration with {nSlice} number of partition ended at time {tEnd} after {tDuration} seconds\")\n",
    "\n",
    "    # Output in the correct memory adresses\n",
    "    totalLogParallelInit[f\"Number of partition\" + str(nSlice)] = logParallelInit\n",
    "    totalLogParallelKmeans[f\"Number of partition\" + str(nSlice)] = logParallelKmeans\n",
    "    tDurationsParallel[f\"Number of partition\" + str(nSlice)] = tDuration\n",
    "    tPreOperationsParallel[f\"Number of partition\" + str(nSlice)] = tPreOperation\n",
    "\n",
    "    #Rdd.unpersist()\n",
    "\n",
    "    spark.catalog.clearCache() \n",
    "    # for (id, rdd) in sc._jsc.getPersistentRDDs().items():\n",
    "    #     rdd.unpersist()\n",
    "    # print(\"Persisted RRDs: \", len(sc._jsc.getPersistentRDDs().items()))\n",
    "\n",
    "\n",
    "    # Compute the total log\n",
    "    logParallel = {\"totalLogParallelInit\": totalLogParallelInit, \"totalLogParallelKmeans\": totalLogParallelKmeans, \"tDurationsParallel\": tDurationsParallel, \"tPreOperationsParallel\": tPreOperationsParallel}\n",
    "    \n",
    "    # Save the log file\n",
    "    if not os.path.exists('dataP'): # create a directory if it doesnt exist\n",
    "        os.makedirs('dataP')\n",
    "    \n",
    "    with open(pickle_fileP, \"wb\") as file:\n",
    "        pickle.dump(logParallel, file)\n",
    "\n",
    "    # Clear the space\n",
    "    subprocess.run(\"ssh slave2 'cd /usr/local/spark/work/ && [ \\\"$(ls -A .)\\\" ] && rm -r ./*'\", shell=True)\n",
    "    subprocess.run(\"ssh slave3 'cd /usr/local/spark/work/ && [ \\\"$(ls -A .)\\\" ] && rm -r ./*'\", shell=True)\n",
    "\n",
    "\n",
    "    ### NAIVE INIT ###\n",
    "    \n",
    "    # Load log if it exists\n",
    "    sleep(1)\n",
    "    if os.path.isfile(pickle_fileR):\n",
    "        with open(pickle_fileR, \"rb\") as f:\n",
    "            logNaive = pickle.load(f)\n",
    "            totalLogNaiveInit, totalLogNaiveKmeans, tDurationsNaive, tPreOperationsNaive = logNaive.values()\n",
    "    else:\n",
    "        totalLogNaiveInit = {}\n",
    "        totalLogNaiveKmeans = {}\n",
    "        tDurationsNaive = {}\n",
    "        tPreOperationsNaive = {}\n",
    "    \n",
    "    # Start algo\n",
    "    tInit = time() # compute the time of the beginning of the iteration over the number of partitions\n",
    "    print(f\"The iteration with {nSlice} number of partition started at time {tInit}\")\n",
    "    \n",
    "    # Parallelize over nSlice partitions\n",
    "    Rdd = sc.parallelize([(None, {\"x\": x[i],\"y\": y[i], \"d2\":None}) for i in range(len(y))], numSlices = nSlice)\n",
    "\n",
    "    # Cut the categorical attributes\n",
    "    Rdd = Rdd.map(deleteBytes)\\\n",
    "             .persist()\n",
    "\n",
    "    # Setting the theoretical number of clusters\n",
    "    kTrue = Rdd.map(lambda datum: datum[1][\"y\"])\\\n",
    "               .distinct()\\\n",
    "               .count()\n",
    "    \n",
    "    # Rescale the RDD over the max\n",
    "    maxS = Rdd.map(lambda datum: datum[1][\"x\"])\\\n",
    "           .reduce(lambda a, b: np.maximum(a, b))\n",
    "    minS = Rdd.map(lambda datum: datum[1][\"x\"])\\\n",
    "           .reduce(lambda a, b: np.minimum(a, b))\n",
    "\n",
    "    Rdd = Rdd.map(lambda datum: minmaxRescale(datum, minS, maxS))\\\n",
    "             .persist()\n",
    "    \n",
    "    # Setting up the input and output information for the algorithm\n",
    "    logNaiveInit = {}\n",
    "    logNaiveKmeans = {}\n",
    "\n",
    "    # Setup k and l\n",
    "    k=kTrue\n",
    "    l=k*2 \n",
    "    \n",
    "    tInitI = time()\n",
    "\n",
    "    tPreOperation = tInitI - tInit\n",
    "    print(f\"Finished the pre-steps after {tPreOperation} seconds\")\n",
    "          \n",
    "    # initialization kMeans//\n",
    "    C_init = naiveInitFromSet(Rdd, k, logNaiveInit)\n",
    "    \n",
    "    tInitialization = time() - tInitI\n",
    "    print(f\"Finished the initialization after {tInitialization} seconds\")\n",
    "    \n",
    "    # Run the k-means algorithm\n",
    "    C = kMeans(Rdd, C_init, lloydsMaxIterations, logNaiveKmeans)\n",
    "    \n",
    "    # Time information\n",
    "    tEnd = time() # compute the time of the end of the iteration over the number of partitions\n",
    "    tDuration = tEnd - tInit\n",
    "    \n",
    "    print(f\"The iteration with {nSlice} number of partition ended at time {tEnd} after {tDuration} seconds\")\n",
    "\n",
    "    # Output in the correct memory adresses\n",
    "    totalLogNaiveInit[f\"Number of partition\" + str(nSlice)] = logNaiveInit\n",
    "    totalLogNaiveKmeans[f\"Number of partition\" + str(nSlice)] = logNaiveKmeans\n",
    "    tDurationsNaive[f\"Number of partition\" + str(nSlice)] = tDuration\n",
    "    tPreOperationsNaive[f\"Number of partition\" + str(nSlice)] = tPreOperation\n",
    "\n",
    "    #Rdd.unpersist()\n",
    "\n",
    "    spark.catalog.clearCache() \n",
    "    # for (id, rdd) in sc._jsc.getPersistentRDDs().items():\n",
    "    #     rdd.unpersist()\n",
    "    # print(\"Persisted RRDs: \", len(sc._jsc.getPersistentRDDs().items()))\n",
    "\n",
    "    # Compute the total log\n",
    "    logNaive = {\"totalLogNaiveInit\": totalLogNaiveInit, \"totalLogNaiveKmeans\": totalLogNaiveKmeans, \"tDurationsNaive\": tDurationsNaive, \"tPreOperationsNaive\": tPreOperationsNaive}\n",
    "    \n",
    "    # Save the log file\n",
    "    if not os.path.exists('dataR'): # create a directory if it doesnt exist\n",
    "        os.makedirs('dataR')\n",
    "    \n",
    "    with open(pickle_fileR, \"wb\") as filer:\n",
    "        pickle.dump(logNaive, filer)\n",
    "\n",
    "    # Clear the space\n",
    "    subprocess.run(\"ssh slave2 'cd /usr/local/spark/work/ && [ \\\"$(ls -A .)\\\" ] && rm -r ./*'\", shell=True)\n",
    "    subprocess.run(\"ssh slave3 'cd /usr/local/spark/work/ && [ \\\"$(ls -A .)\\\" ] && rm -r ./*'\", shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "455f721f-cd5d-4f48-be41-66fddf85b878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'totalLogParallelInit': {'Number of partition2': {'tSamples': [0.9625167846679688,\n",
       "    1.102644920349121,\n",
       "    1.056347370147705,\n",
       "    1.0816810131072998,\n",
       "    1.0999093055725098,\n",
       "    1.1076600551605225,\n",
       "    1.1391963958740234,\n",
       "    1.1393795013427734,\n",
       "    1.145113229751587,\n",
       "    1.0341508388519287,\n",
       "    0.992769718170166,\n",
       "    1.0650136470794678,\n",
       "    1.0378704071044922],\n",
       "   'tCentroids': [34.30888915061951,\n",
       "    58.26218247413635,\n",
       "    85.10184264183044,\n",
       "    108.61568975448608,\n",
       "    133.30386662483215,\n",
       "    161.54800367355347,\n",
       "    186.69220972061157,\n",
       "    214.4812912940979,\n",
       "    238.2676498889923,\n",
       "    269.3384690284729,\n",
       "    296.69858288764954,\n",
       "    327.43224453926086,\n",
       "    345.6207664012909],\n",
       "   'CostInit': [891555.5554243359,\n",
       "    20459.66555650932,\n",
       "    9781.530894359516,\n",
       "    5471.4048364394,\n",
       "    4303.815164680175,\n",
       "    3489.5419803761797,\n",
       "    2790.4851080146254,\n",
       "    2501.6291871887997,\n",
       "    2191.7318527853213,\n",
       "    1964.2360937496173,\n",
       "    1781.205574382117,\n",
       "    1635.3199696277575,\n",
       "    1508.1708678204322,\n",
       "    1436.3823164238308],\n",
       "   'tTotal': 2865.9970383644104},\n",
       "  'Number of partition4': {'tSamples': [0.9215764999389648,\n",
       "    0.6994583606719971,\n",
       "    0.8443028926849365,\n",
       "    0.7613179683685303,\n",
       "    0.7833645343780518,\n",
       "    0.850632905960083,\n",
       "    0.7007181644439697,\n",
       "    0.7766401767730713,\n",
       "    0.8510522842407227,\n",
       "    0.7504739761352539,\n",
       "    0.7306036949157715,\n",
       "    0.8200695514678955,\n",
       "    0.6922118663787842,\n",
       "    0.8414125442504883],\n",
       "   'tCentroids': [16.64103055000305,\n",
       "    34.808424949645996,\n",
       "    45.57572865486145,\n",
       "    60.951319456100464,\n",
       "    79.42096590995789,\n",
       "    99.8666250705719,\n",
       "    100.75223994255066,\n",
       "    119.40891742706299,\n",
       "    133.61204171180725,\n",
       "    152.32617163658142,\n",
       "    164.16053318977356,\n",
       "    175.50111556053162,\n",
       "    189.5864188671112,\n",
       "    215.94701099395752],\n",
       "   'CostInit': [2223256.496517683,\n",
       "    36215.8956905895,\n",
       "    10684.122836412404,\n",
       "    6452.302401738859,\n",
       "    4412.758954600249,\n",
       "    3708.5894701573516,\n",
       "    3070.3301820980923,\n",
       "    2574.24333440423,\n",
       "    2184.401702903001,\n",
       "    1957.747703654758,\n",
       "    1804.3832653326385,\n",
       "    1645.942482055228,\n",
       "    1508.0962418151798,\n",
       "    1362.655952837853,\n",
       "    1266.0378064466142],\n",
       "   'tTotal': 1828.3410413265228},\n",
       "  'Number of partition8': {'tSamples': [0.6151382923126221,\n",
       "    0.6074755191802979,\n",
       "    0.878748893737793,\n",
       "    0.729607343673706,\n",
       "    0.8757064342498779,\n",
       "    0.627272367477417,\n",
       "    0.6439237594604492,\n",
       "    0.7628679275512695,\n",
       "    0.759488582611084,\n",
       "    0.7686419486999512,\n",
       "    0.7095768451690674,\n",
       "    0.7184281349182129,\n",
       "    0.6853652000427246],\n",
       "   'tCentroids': [12.719097375869751,\n",
       "    21.513208627700806,\n",
       "    29.81675362586975,\n",
       "    37.82208800315857,\n",
       "    43.242194175720215,\n",
       "    50.18489694595337,\n",
       "    55.687182903289795,\n",
       "    65.69015073776245,\n",
       "    70.30152869224548,\n",
       "    81.97577857971191,\n",
       "    86.6036787033081,\n",
       "    93.74451971054077,\n",
       "    95.11416101455688],\n",
       "   'CostInit': [891555.5554263061,\n",
       "    43032.54575564116,\n",
       "    8243.625264036864,\n",
       "    5041.82595719757,\n",
       "    3939.922506969294,\n",
       "    3323.1494872599396,\n",
       "    2874.486765935351,\n",
       "    2570.7759360479404,\n",
       "    2226.4886530578515,\n",
       "    1970.66772097917,\n",
       "    1782.0553402720057,\n",
       "    1617.7478994458982,\n",
       "    1533.0650610150462,\n",
       "    1438.6996884454643],\n",
       "   'tTotal': 867.0143704414368},\n",
       "  'Number of partition16': {'tSamples': [0.7457842826843262,\n",
       "    0.8467836380004883,\n",
       "    1.0361840724945068,\n",
       "    0.7181484699249268,\n",
       "    0.7262876033782959,\n",
       "    0.6795456409454346,\n",
       "    0.7585532665252686,\n",
       "    0.853304386138916,\n",
       "    0.8150820732116699,\n",
       "    0.6085448265075684,\n",
       "    0.6973884105682373,\n",
       "    0.7756650447845459,\n",
       "    0.6554012298583984],\n",
       "   'tCentroids': [12.95324158668518,\n",
       "    21.266608476638794,\n",
       "    30.047996044158936,\n",
       "    37.82631850242615,\n",
       "    43.358097314834595,\n",
       "    50.17147397994995,\n",
       "    58.87712240219116,\n",
       "    64.02612900733948,\n",
       "    72.64078545570374,\n",
       "    79.60007190704346,\n",
       "    87.75814437866211,\n",
       "    95.11174821853638,\n",
       "    101.40671038627625],\n",
       "   'CostInit': [891555.5554243803,\n",
       "    23841.414180545613,\n",
       "    8213.866518808329,\n",
       "    5277.333497840999,\n",
       "    4097.926163642866,\n",
       "    3316.363092715657,\n",
       "    2791.599921738104,\n",
       "    2321.54102208872,\n",
       "    2010.303609892069,\n",
       "    1824.9644993253667,\n",
       "    1703.6156078430513,\n",
       "    1534.306536976424,\n",
       "    1421.7349249925762,\n",
       "    1347.0105904909935],\n",
       "   'tTotal': 883.1258635520935},\n",
       "  'Number of partition32': {'tSamples': [0.8852734565734863,\n",
       "    0.8810276985168457,\n",
       "    0.8625168800354004,\n",
       "    0.9244987964630127,\n",
       "    0.8262588977813721,\n",
       "    0.8728294372558594,\n",
       "    0.972790002822876,\n",
       "    1.1449611186981201,\n",
       "    1.0454034805297852,\n",
       "    0.7826855182647705,\n",
       "    0.7583081722259521,\n",
       "    0.7540431022644043,\n",
       "    0.8230299949645996,\n",
       "    0.889915943145752],\n",
       "   'tCentroids': [12.478426933288574,\n",
       "    21.142208576202393,\n",
       "    28.262879133224487,\n",
       "    35.81976652145386,\n",
       "    44.096577644348145,\n",
       "    46.74890637397766,\n",
       "    54.351006746292114,\n",
       "    59.872719287872314,\n",
       "    67.86278796195984,\n",
       "    76.05911302566528,\n",
       "    80.90020155906677,\n",
       "    87.12190914154053,\n",
       "    95.74686551094055,\n",
       "    103.99246287345886],\n",
       "   'CostInit': [1601525.631138093,\n",
       "    36422.66509834645,\n",
       "    11332.489841424569,\n",
       "    6418.884832234001,\n",
       "    4494.588517851984,\n",
       "    3620.533530831383,\n",
       "    2927.1547946761225,\n",
       "    2625.131950200434,\n",
       "    2336.6499837487345,\n",
       "    2042.2631394949858,\n",
       "    1824.1950300361175,\n",
       "    1706.8626305367907,\n",
       "    1574.8324718237725,\n",
       "    1454.8454307513075,\n",
       "    1380.7837124088487],\n",
       "   'tTotal': 944.2547388076782},\n",
       "  'Number of partition64': {'tSamples': [1.040752649307251,\n",
       "    2.697918653488159,\n",
       "    1.2310497760772705,\n",
       "    1.1457545757293701,\n",
       "    1.1294238567352295,\n",
       "    1.0526211261749268,\n",
       "    1.0642776489257812,\n",
       "    1.2494275569915771,\n",
       "    1.0550503730773926,\n",
       "    1.136256217956543,\n",
       "    1.062037706375122,\n",
       "    1.2037811279296875,\n",
       "    1.0261390209197998],\n",
       "   'tCentroids': [15.783437013626099,\n",
       "    24.676029443740845,\n",
       "    34.15475416183472,\n",
       "    41.430190086364746,\n",
       "    49.258504152297974,\n",
       "    56.03084850311279,\n",
       "    65.58416414260864,\n",
       "    71.16828656196594,\n",
       "    75.1758918762207,\n",
       "    88.91112852096558,\n",
       "    92.14052128791809,\n",
       "    100.45680642127991,\n",
       "    107.39791083335876],\n",
       "   'CostInit': [1062852.2618626256,\n",
       "    38273.93460782226,\n",
       "    12155.186444581577,\n",
       "    6052.731142487753,\n",
       "    4312.795327739573,\n",
       "    3313.457238318669,\n",
       "    2744.661574159211,\n",
       "    2378.2397601518314,\n",
       "    2191.9692388391827,\n",
       "    1996.6224044787161,\n",
       "    1750.9074866120927,\n",
       "    1542.2359614073866,\n",
       "    1452.1573946410706,\n",
       "    1346.7982019708827],\n",
       "   'tTotal': 962.8499879837036},\n",
       "  'Number of partition128': {'tSamples': [1.897202968597412,\n",
       "    1.864509105682373,\n",
       "    1.7935700416564941,\n",
       "    1.890960454940796,\n",
       "    1.621436595916748,\n",
       "    2.236666679382324,\n",
       "    2.742197275161743,\n",
       "    1.9170715808868408,\n",
       "    2.0783205032348633,\n",
       "    1.8538992404937744,\n",
       "    1.8007802963256836,\n",
       "    1.6705656051635742,\n",
       "    1.891143560409546],\n",
       "   'tCentroids': [16.035709857940674,\n",
       "    21.85193181037903,\n",
       "    28.844789743423462,\n",
       "    36.06940937042236,\n",
       "    41.123462200164795,\n",
       "    52.65567588806152,\n",
       "    57.337970495224,\n",
       "    66.71704840660095,\n",
       "    73.60794806480408,\n",
       "    82.48618292808533,\n",
       "    89.59514474868774,\n",
       "    93.68514966964722,\n",
       "    101.67698192596436],\n",
       "   'CostInit': [843029.9190250103,\n",
       "    27351.537221166454,\n",
       "    11242.124424030668,\n",
       "    6356.412158202355,\n",
       "    4621.567039394056,\n",
       "    3735.86370580881,\n",
       "    2788.2916503841225,\n",
       "    2432.2613381331244,\n",
       "    2163.290411333133,\n",
       "    1898.8189610404204,\n",
       "    1756.5841518622667,\n",
       "    1622.8440617936703,\n",
       "    1535.2785779259714,\n",
       "    1413.8926054028611],\n",
       "   'tTotal': 909.8004159927368},\n",
       "  'Number of partition256': {'tSamples': [3.1861677169799805,\n",
       "    2.9346539974212646,\n",
       "    3.330536127090454,\n",
       "    3.3047173023223877,\n",
       "    4.279085636138916,\n",
       "    3.634370803833008,\n",
       "    3.3302865028381348,\n",
       "    3.950125217437744,\n",
       "    3.3546864986419678,\n",
       "    3.269099712371826,\n",
       "    3.087632894515991,\n",
       "    3.3365933895111084,\n",
       "    3.324103593826294,\n",
       "    2.8914616107940674],\n",
       "   'tCentroids': [15.801616907119751,\n",
       "    23.82721495628357,\n",
       "    31.761763334274292,\n",
       "    39.45038414001465,\n",
       "    47.18132305145264,\n",
       "    54.80671572685242,\n",
       "    62.700706481933594,\n",
       "    68.5137357711792,\n",
       "    73.2292697429657,\n",
       "    84.16423416137695,\n",
       "    87.31322836875916,\n",
       "    99.012535572052,\n",
       "    103.04088735580444,\n",
       "    106.78263211250305],\n",
       "   'CostInit': [2094763.126227179,\n",
       "    27878.409160031915,\n",
       "    10658.326732584896,\n",
       "    5833.35723370825,\n",
       "    4096.928090576835,\n",
       "    3379.1370287767904,\n",
       "    2881.738645298614,\n",
       "    2389.2175449394863,\n",
       "    2161.911762542489,\n",
       "    1949.5562487230236,\n",
       "    1798.4327112237133,\n",
       "    1711.6371445157595,\n",
       "    1588.4874406354181,\n",
       "    1489.8582020749977,\n",
       "    1400.6066085749405],\n",
       "   'tTotal': 1078.2118146419525}},\n",
       " 'totalLogParallelKmeans': {'Number of partition2': {'CostsKmeans': [12939.60542773388,\n",
       "    12851.716300619773,\n",
       "    12826.159551470528,\n",
       "    12815.38330833875],\n",
       "   'tIterations': [27.540646076202393,\n",
       "    26.30562114715576,\n",
       "    24.978158712387085,\n",
       "    24.558554887771606],\n",
       "   'tTotal': 103.38298988342285},\n",
       "  'Number of partition4': {'CostsKmeans': [13517.10731572274,\n",
       "    13479.675566855436,\n",
       "    13434.154226170805,\n",
       "    13402.227211106478,\n",
       "    13365.486827999353,\n",
       "    13297.993836318275,\n",
       "    13171.59309801857,\n",
       "    13073.518642289844,\n",
       "    13010.458301522356,\n",
       "    12984.423626841555,\n",
       "    12973.634995359225],\n",
       "   'tIterations': [13.647939205169678,\n",
       "    12.686150550842285,\n",
       "    13.542422771453857,\n",
       "    12.75775694847107,\n",
       "    12.507908582687378,\n",
       "    13.420222759246826,\n",
       "    12.637624025344849,\n",
       "    12.846412420272827,\n",
       "    13.059520244598389,\n",
       "    12.598021268844604,\n",
       "    12.479304313659668],\n",
       "   'tTotal': 142.1833052635193},\n",
       "  'Number of partition8': {'CostsKmeans': [17814.702542049774,\n",
       "    17736.639720645293,\n",
       "    17680.464509828547,\n",
       "    17665.363920586773],\n",
       "   'tIterations': [10.632622718811035,\n",
       "    9.43280291557312,\n",
       "    9.708833456039429,\n",
       "    9.707727670669556],\n",
       "   'tTotal': 39.48199701309204},\n",
       "  'Number of partition16': {'CostsKmeans': [16672.777101442378,\n",
       "    16630.988194838086,\n",
       "    16620.408530647885],\n",
       "   'tIterations': [11.506594181060791, 11.083604574203491, 10.004601240158081],\n",
       "   'tTotal': 32.594807386398315},\n",
       "  'Number of partition32': {'CostsKmeans': [18290.38698340803,\n",
       "    18247.130683849235,\n",
       "    18231.941709712864],\n",
       "   'tIterations': [12.609870672225952, 11.976198673248291, 11.584292888641357],\n",
       "   'tTotal': 36.170369148254395},\n",
       "  'Number of partition64': {'CostsKmeans': [12937.075454477777,\n",
       "    12880.160682555017,\n",
       "    12738.745767102295,\n",
       "    12627.31110043523,\n",
       "    12597.453037016438,\n",
       "    12541.210416507418,\n",
       "    12436.30954394765,\n",
       "    12320.802906720284,\n",
       "    12208.047517246077,\n",
       "    12015.72904710026,\n",
       "    12012.940760893664],\n",
       "   'tIterations': [14.405490636825562,\n",
       "    13.785751819610596,\n",
       "    13.512104988098145,\n",
       "    13.697131395339966,\n",
       "    13.227606773376465,\n",
       "    14.718658447265625,\n",
       "    13.325359582901001,\n",
       "    13.133517265319824,\n",
       "    13.50083327293396,\n",
       "    13.349402904510498,\n",
       "    13.336174011230469],\n",
       "   'tTotal': 149.99205541610718},\n",
       "  'Number of partition128': {'CostsKmeans': [14981.958557733438,\n",
       "    14923.590525057996,\n",
       "    14899.172029911586,\n",
       "    14885.518877645756],\n",
       "   'tIterations': [16.278069972991943,\n",
       "    16.208036184310913,\n",
       "    15.838127613067627,\n",
       "    15.776582956314087],\n",
       "   'tTotal': 64.10082530975342},\n",
       "  'Number of partition256': {'CostsKmeans': [12899.577666046136,\n",
       "    12837.91670272878,\n",
       "    12823.832650698254,\n",
       "    12812.987736309531],\n",
       "   'tIterations': [20.962383031845093,\n",
       "    20.874452352523804,\n",
       "    20.48980736732483,\n",
       "    20.33723473548889],\n",
       "   'tTotal': 82.66389608383179}},\n",
       " 'tDurationsParallel': {'Number of partition2': 2986.947148323059,\n",
       "  'Number of partition4': 1983.6519553661346,\n",
       "  'Number of partition8': 916.7358276844025,\n",
       "  'Number of partition16': 928.085417509079,\n",
       "  'Number of partition32': 993.0159313678741,\n",
       "  'Number of partition64': 1127.9309484958649,\n",
       "  'Number of partition128': 993.1310834884644,\n",
       "  'Number of partition256': 1186.840815782547},\n",
       " 'tPreOperationsParallel': {'Number of partition2': 17.566948890686035,\n",
       "  'Number of partition4': 13.127323150634766,\n",
       "  'Number of partition8': 10.239272356033325,\n",
       "  'Number of partition16': 12.36444902420044,\n",
       "  'Number of partition32': 12.590649127960205,\n",
       "  'Number of partition64': 15.08873963356018,\n",
       "  'Number of partition128': 19.22950291633606,\n",
       "  'Number of partition256': 25.964742422103882}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ef580eb-8b27-4f84-b945-ef50a91bd244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'totalLogNaiveInit': {'Number of partition2': {'tTotal': 3.5391743183135986},\n",
       "  'Number of partition4': {'tTotal': 2.372647285461426},\n",
       "  'Number of partition8': {'tTotal': 1.561168909072876},\n",
       "  'Number of partition16': {'tTotal': 1.9718973636627197},\n",
       "  'Number of partition32': {'tTotal': 2.4401488304138184},\n",
       "  'Number of partition64': {'tTotal': 3.2234396934509277},\n",
       "  'Number of partition128': {'tTotal': 5.893186569213867},\n",
       "  'Number of partition256': {'tTotal': 9.937079906463623}},\n",
       " 'totalLogNaiveKmeans': {'Number of partition2': {'CostsKmeans': [42516.03346356709,\n",
       "    30489.899569214176,\n",
       "    28870.557007268813,\n",
       "    27552.014438794737,\n",
       "    23278.24060503552,\n",
       "    18984.3147713026,\n",
       "    18760.240816989506,\n",
       "    18693.13101953215,\n",
       "    18670.316806382605,\n",
       "    18655.67316314641],\n",
       "   'tIterations': [23.019476652145386,\n",
       "    20.80378556251526,\n",
       "    23.17156481742859,\n",
       "    21.14793062210083,\n",
       "    21.443459510803223,\n",
       "    20.854639530181885,\n",
       "    21.03282380104065,\n",
       "    20.922189474105835,\n",
       "    20.995289087295532,\n",
       "    21.1844801902771],\n",
       "   'tTotal': 214.5756607055664},\n",
       "  'Number of partition4': {'CostsKmeans': [155320.87780776434,\n",
       "    69808.04708340974,\n",
       "    54725.117012482755,\n",
       "    43558.38585393489,\n",
       "    42153.973898581025,\n",
       "    39892.612618343206,\n",
       "    36677.77841012569,\n",
       "    36601.76233647565,\n",
       "    36533.77835639385,\n",
       "    36487.0518173548,\n",
       "    36465.68111002703],\n",
       "   'tIterations': [11.739044666290283,\n",
       "    8.802425622940063,\n",
       "    8.781042098999023,\n",
       "    8.864035367965698,\n",
       "    8.840255498886108,\n",
       "    8.699027061462402,\n",
       "    9.077954292297363,\n",
       "    9.029659032821655,\n",
       "    8.719668626785278,\n",
       "    8.840396165847778,\n",
       "    8.62808632850647],\n",
       "   'tTotal': 100.02161884307861},\n",
       "  'Number of partition8': {'CostsKmeans': [82567.0250963437,\n",
       "    33104.67062765449,\n",
       "    31797.197127739524,\n",
       "    30862.86104723941,\n",
       "    30695.516272739696,\n",
       "    30633.602145267392,\n",
       "    30564.992296609005,\n",
       "    30482.895593478763,\n",
       "    30440.947605577367,\n",
       "    30416.90273136094],\n",
       "   'tIterations': [9.110820293426514,\n",
       "    8.155208110809326,\n",
       "    8.114148616790771,\n",
       "    8.752028465270996,\n",
       "    8.269132137298584,\n",
       "    8.542954683303833,\n",
       "    8.35365915298462,\n",
       "    8.215005874633789,\n",
       "    8.737047910690308,\n",
       "    8.661136627197266],\n",
       "   'tTotal': 84.91116189956665},\n",
       "  'Number of partition16': {'CostsKmeans': [166384.53462033137,\n",
       "    65895.6056307083,\n",
       "    65706.02173432914,\n",
       "    65383.54430620918,\n",
       "    52128.157728599246,\n",
       "    45756.44843686664,\n",
       "    43376.97766168073,\n",
       "    42947.12896710763,\n",
       "    42930.39892842658],\n",
       "   'tIterations': [9.962773323059082,\n",
       "    7.898746490478516,\n",
       "    8.806572198867798,\n",
       "    8.205958127975464,\n",
       "    8.057426929473877,\n",
       "    8.033643007278442,\n",
       "    7.885922193527222,\n",
       "    8.117125988006592,\n",
       "    8.29460096359253],\n",
       "   'tTotal': 75.26278877258301},\n",
       "  'Number of partition32': {'CostsKmeans': [49520.386358362106,\n",
       "    30527.58542146165,\n",
       "    23020.67136604504,\n",
       "    21911.73349150853,\n",
       "    21754.20134667065,\n",
       "    21737.064097228238],\n",
       "   'tIterations': [9.609509706497192,\n",
       "    8.901917934417725,\n",
       "    9.331801414489746,\n",
       "    8.851065158843994,\n",
       "    9.658641338348389,\n",
       "    9.07851266860962],\n",
       "   'tTotal': 55.43146347999573},\n",
       "  'Number of partition64': {'CostsKmeans': [139644.47538727487,\n",
       "    36535.13405139362,\n",
       "    33452.63488532336,\n",
       "    32223.7184884443,\n",
       "    31195.288436264193,\n",
       "    31096.484073064148,\n",
       "    31059.985512694115,\n",
       "    30952.39837918774,\n",
       "    30697.26167899626,\n",
       "    30519.036479392384,\n",
       "    30363.737355164907,\n",
       "    30089.833440770697,\n",
       "    29614.347467224787,\n",
       "    29549.847534218025,\n",
       "    29539.846943083],\n",
       "   'tIterations': [11.415151834487915,\n",
       "    9.910670280456543,\n",
       "    9.977519750595093,\n",
       "    10.196448564529419,\n",
       "    9.884084701538086,\n",
       "    13.72800874710083,\n",
       "    10.122002363204956,\n",
       "    10.24148416519165,\n",
       "    10.084786653518677,\n",
       "    9.885781049728394,\n",
       "    9.697957038879395,\n",
       "    10.019073247909546,\n",
       "    10.047260284423828,\n",
       "    9.607266664505005,\n",
       "    9.947824954986572],\n",
       "   'tTotal': 154.76535058021545},\n",
       "  'Number of partition128': {'CostsKmeans': [37588.1663885156,\n",
       "    26849.463446228598,\n",
       "    25295.796181492988,\n",
       "    24023.460059451285,\n",
       "    22624.61694974428,\n",
       "    22344.19222911269,\n",
       "    22278.733899910447,\n",
       "    22222.518277534593,\n",
       "    22182.328120225702,\n",
       "    22048.96907256953,\n",
       "    21939.82526507445,\n",
       "    21863.338224566698,\n",
       "    21551.51639223278,\n",
       "    21176.682198915856,\n",
       "    20696.410448243634,\n",
       "    20654.242605739488,\n",
       "    20646.015374805942],\n",
       "   'tIterations': [14.287910223007202,\n",
       "    13.228873491287231,\n",
       "    17.510481595993042,\n",
       "    13.066452980041504,\n",
       "    13.23490309715271,\n",
       "    12.785268068313599,\n",
       "    14.503814935684204,\n",
       "    13.622087478637695,\n",
       "    13.498777866363525,\n",
       "    14.063764572143555,\n",
       "    12.646893739700317,\n",
       "    12.741609811782837,\n",
       "    12.875558853149414,\n",
       "    13.131840944290161,\n",
       "    12.990589141845703,\n",
       "    13.212323188781738,\n",
       "    13.01498556137085],\n",
       "   'tTotal': 230.41616916656494},\n",
       "  'Number of partition256': {'CostsKmeans': [155888.09765600174,\n",
       "    63416.33422365386,\n",
       "    44822.84167562508,\n",
       "    35598.0319125052,\n",
       "    33770.97849253809,\n",
       "    33674.87549087495,\n",
       "    33436.713912610074,\n",
       "    30595.98345517677,\n",
       "    27523.66806397265,\n",
       "    27327.893091206286,\n",
       "    27266.891809429766,\n",
       "    27251.758602438957],\n",
       "   'tIterations': [20.478190660476685,\n",
       "    18.005467891693115,\n",
       "    18.476536512374878,\n",
       "    18.06768298149109,\n",
       "    18.637913465499878,\n",
       "    18.73542594909668,\n",
       "    18.836506128311157,\n",
       "    17.898898363113403,\n",
       "    17.84649634361267,\n",
       "    17.95285153388977,\n",
       "    18.714391708374023,\n",
       "    18.070369005203247],\n",
       "   'tTotal': 221.72075271606445}},\n",
       " 'tDurationsNaive': {'Number of partition2': 234.11635303497314,\n",
       "  'Number of partition4': 112.04262280464172,\n",
       "  'Number of partition8': 95.04203844070435,\n",
       "  'Number of partition16': 87.0266945362091,\n",
       "  'Number of partition32': 67.21444606781006,\n",
       "  'Number of partition64': 169.2202067375183,\n",
       "  'Number of partition128': 251.33056569099426,\n",
       "  'Number of partition256': 252.59647250175476},\n",
       " 'tPreOperationsNaive': {'Number of partition2': 16.00133228302002,\n",
       "  'Number of partition4': 9.64820408821106,\n",
       "  'Number of partition8': 8.569549083709717,\n",
       "  'Number of partition16': 9.791845083236694,\n",
       "  'Number of partition32': 9.342713594436646,\n",
       "  'Number of partition64': 11.231264591217041,\n",
       "  'Number of partition128': 15.021092891693115,\n",
       "  'Number of partition256': 20.938359260559082}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logNaive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59be8588-13da-4d15-b551-3b64462412b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kill spark and the context\n",
    "sc.stop()\n",
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17473b2-7f02-43a5-81fa-b970fc813216",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
